{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3614c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution № 1\n",
      "Sum of 1 to 10000000000000000000000000:\n",
      " 50000000000000000000000005000000000000000000000000\n",
      "Execution time: 0.000000 seconds\n",
      "\n",
      "________________________\n",
      "\n",
      "\n",
      "Solution № 2\n",
      "Enter number (N) => 5\n",
      "The sum of the numbers from 1 to 5 is 15\n",
      "Program runtime: 0.1 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task # 1\n",
    "\n",
    "# Solution № 1\n",
    "import time\n",
    "def sum_N(N):\n",
    "    start_time = time.time()\n",
    "    total = (N * (N + 1)) // 2\n",
    "    end_time = time.time()\n",
    "    print('Solution № 1')\n",
    "    print(f\"Sum of 1 to {N}:\\n {total}\")\n",
    "    print(f\"Execution time: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "\n",
    "N = 10**25\n",
    "\"\"\"\n",
    "N = int(1.0e25)\n",
    "Неверый ответ, из-за неточного\n",
    "представления действительных чисел.\n",
    "\"\"\"\n",
    "\n",
    "sum_N(N)\n",
    "print(\"\\n________________________\\n\")\n",
    "\n",
    "###############\n",
    "\n",
    "# Solution № 2\n",
    "print('Solution № 2')\n",
    "N = int(input('Enter number (N) => '))\n",
    "result = 0\n",
    "for i in range(N + 1):\n",
    "    result += i\n",
    "# замеряем время начала выполнения программы\n",
    "start_time = time.time()\n",
    "time.sleep(0.1)\n",
    "# вычисляем сумму\n",
    "sum_of_numbers = result\n",
    "\n",
    "# замеряем время окончания выполнения программы\n",
    "end_time = time.time()\n",
    "print(\"The sum of the numbers from 1 to\", N, \"is\", result)\n",
    "print('Program runtime:', round(end_time - start_time, 1), 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4597993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution № 1\n",
      "Number of islands in matrix_one ->  2\n",
      "Number of islands in matrix_two ->  3\n",
      "Number of islands in matrix_three ->  2\n",
      "Solution № 2\n",
      "\n",
      "Solution № 2\n",
      "Number of islands in matrix_first ->  3\n",
      "Number of islands in matrix_second ->  1\n",
      "Number of islands in matrix_third ->  3\n"
     ]
    }
   ],
   "source": [
    "# Task # 2\n",
    "\n",
    "# Solution № 1\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Create matrix\n",
    "matrix_one = np.array([[0, 1, 0],\n",
    "                   [0, 0, 0],\n",
    "                   [0, 1, 1]])\n",
    "\n",
    "# Search for similar components\n",
    "labels_one, num_one = label(matrix_one)\n",
    "\n",
    "# Outputting the result\n",
    "print('Solution № 1')\n",
    "print('Number of islands in matrix_one -> ', num_one)\n",
    "##############################################\n",
    "\n",
    "# Create matrix\n",
    "matrix_two = np.array([[0, 0, 0, 1],\n",
    "                   [0, 0, 1, 0],\n",
    "                   [0, 1, 0, 0]])\n",
    "\n",
    "# Search for similar components\n",
    "labels_two, num_two = label(matrix_two)\n",
    "\n",
    "# Outputting the result\n",
    "print('Number of islands in matrix_two -> ', num_two)\n",
    "###############################################\n",
    "\n",
    "# Create matrix\n",
    "matrix_three = np.array([[0, 0, 0, 1],\n",
    "                   [0, 0, 1, 1],\n",
    "                   [1, 0, 0, 1]])\n",
    "\n",
    "# Search for similar components\n",
    "labels_three, num_three = label(matrix_three)\n",
    "\n",
    "# Outputting the result\n",
    "print('Number of islands in matrix_three -> ', num_three)\n",
    "\n",
    "# Solution № 2\n",
    "#### Random matrix\n",
    "\n",
    "# Create matrix first   \n",
    "matrix_first_rnd = np.random.randint(2, size=(3, 3))\n",
    "# Search for similar components\n",
    "labels_first, first = label(matrix_first_rnd)\n",
    "print('Solution № 2')\n",
    "# Outputting the result\n",
    "print('\\nSolution № 2')\n",
    "print('Number of islands in matrix_first -> ', first)\n",
    "    \n",
    "    \n",
    "# Create matrix second\n",
    "matrix_second_rnd = np.random.randint(2, size=(3, 4))\n",
    "# Search for similar components\n",
    "labels_second, second = label(matrix_second_rnd)\n",
    "# Outputting the result\n",
    "print('Number of islands in matrix_second -> ', second)\n",
    "\n",
    "# Create matrix third\n",
    "matrix_third_rnd = np.random.randint(2, size=(3, 4))\n",
    "# Search for similar components\n",
    "labels_three, third = label(matrix_third_rnd)\n",
    "# Outputting the result\n",
    "print('Number of islands in matrix_third -> ', third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c9b4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a model on the data \"internship_train\" (90 000)\n",
      "Comparison of actual values ​​with predicted values\n",
      "           Actual  Predicted\n",
      "66710  62.575089  49.555446\n",
      "73507  64.309420  51.331851\n",
      "43477  63.401720  50.027803\n",
      "74967  69.481498  50.129235\n",
      "52417  45.798254  50.664569\n",
      "...          ...        ...\n",
      "40943  47.728598  49.051494\n",
      "60801  11.116102  49.655734\n",
      "75479  48.054846  50.360042\n",
      "63419  69.792890  48.802427\n",
      "54572  11.990785  50.173180\n",
      "\n",
      "[27000 rows x 2 columns]\n",
      "\n",
      " Descriptive statistics \"internship_train\"\n",
      "              Actual     Predicted\n",
      "count  27000.000000  27000.000000\n",
      "mean      50.097039     50.010425\n",
      "std       28.889054      0.832720\n",
      "min        0.002634     46.391340\n",
      "25%       25.149349     49.440774\n",
      "50%       50.076375     50.007223\n",
      "75%       75.236566     50.573833\n",
      "max       99.990529     53.045751\n",
      "\n",
      "Root Mean Squared Error:\n",
      " 28.8969246791539\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 Actual   R-squared (uncentered):                   0.750\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.750\n",
      "Method:                 Least Squares   F-statistic:                          8.113e+04\n",
      "Date:                Fri, 10 Mar 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        20:47:32   Log-Likelihood:                     -1.2913e+05\n",
      "No. Observations:               27000   AIC:                                  2.583e+05\n",
      "Df Residuals:                   26999   BIC:                                  2.583e+05\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Predicted      1.0015      0.004    284.836      0.000       0.995       1.008\n",
      "==============================================================================\n",
      "Omnibus:                    24379.809   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1627.292\n",
      "Skew:                          -0.008   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.797   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Data normalization \"internship_train\" (90 000)\n",
      "Comparison of actual values ​​with predicted values\n",
      "          Actual  Predicted\n",
      "0      0.625744   0.495544\n",
      "1      0.643088   0.513308\n",
      "2      0.634011   0.500267\n",
      "3      0.694811   0.501282\n",
      "4      0.457971   0.506635\n",
      "...         ...        ...\n",
      "26995  0.477275   0.490504\n",
      "26996  0.111138   0.496547\n",
      "26997  0.480537   0.503590\n",
      "26998  0.697925   0.488013\n",
      "26999  0.119885   0.501721\n",
      "\n",
      "[27000 rows x 2 columns]\n",
      "\n",
      " Descriptive statistics data normalization\n",
      "              Actual     Predicted\n",
      "count  27000.000000  27000.000000\n",
      "mean       0.500960      0.500094\n",
      "std        0.288900      0.008327\n",
      "min        0.000000      0.463902\n",
      "25%        0.251475      0.494397\n",
      "50%        0.500753      0.500062\n",
      "75%        0.752363      0.505728\n",
      "max        0.999910      0.530448\n",
      "\n",
      "Root Mean Squared Error:\n",
      " 0.2889783559202238\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 Actual   R-squared (uncentered):                   0.750\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.750\n",
      "Method:                 Least Squares   F-statistic:                          8.112e+04\n",
      "Date:                Fri, 10 Mar 2023   Prob (F-statistic):                        0.00\n",
      "Time:                        20:47:32   Log-Likelihood:                         -4793.4\n",
      "No. Observations:               27000   AIC:                                      9589.\n",
      "Df Residuals:                   26999   BIC:                                      9597.\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Predicted      1.0015      0.004    284.821      0.000       0.995       1.008\n",
      "==============================================================================\n",
      "Omnibus:                    24379.809   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1627.292\n",
      "Skew:                          -0.008   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.797   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Creating a model on the data \"internship_hidden_test\" (10 000)\n",
      "              0\n",
      "0     48.317272\n",
      "1     50.791205\n",
      "2     50.149234\n",
      "3     48.824211\n",
      "4     49.968150\n",
      "...         ...\n",
      "9995  47.961489\n",
      "9996  51.339136\n",
      "9997  51.089768\n",
      "9998  50.403963\n",
      "9999  50.348286\n",
      "\n",
      "[10000 rows x 1 columns]\n",
      "\n",
      " Descriptive statistics\n",
      "                   0\n",
      "count  10000.000000\n",
      "mean      50.025442\n",
      "std        0.843145\n",
      "min       46.359431\n",
      "25%       49.452516\n",
      "50%       50.035162\n",
      "75%       50.590018\n",
      "max       53.291459\n"
     ]
    }
   ],
   "source": [
    "# Task # 3\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "intern_train = pd.read_csv('C:\\\\Users\\\\pipem\\\\Desktop\\\\Study\\\\Quantum internship\\\\internship_train.csv')\n",
    "\n",
    "#######################\n",
    "print('\\nCreating a model on the data \"internship_train\" (90 000)')\n",
    "# Creating a model on the data 'internship_train' (90 000)\n",
    "# Allocation of variables for model building\n",
    "X = intern_train.iloc[:, 0:53]\n",
    "y = intern_train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "regress = LinearRegression() \n",
    "regress.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred = regress.predict(X_test)\n",
    "\n",
    "# Comparison of actual values ​​with predicted values\n",
    "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}) \n",
    "print('Comparison of actual values ​​with predicted values\\n', \n",
    "      comparison)\n",
    "print('\\n Descriptive statistics \"internship_train\"\\n', comparison.describe())\n",
    "\n",
    "print('\\nRoot Mean Squared Error:\\n', \n",
    "      np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "model = sm.OLS(comparison['Actual'], comparison['Predicted'])\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "#################\n",
    "print('\\nData normalization \"internship_train\" (90 000)')\n",
    "# Data normalization\n",
    "scaler = MinMaxScaler()\n",
    "intern_train_norm = scaler.fit_transform(intern_train)\n",
    "\n",
    "# Creating a model with normalized data\n",
    "# Allocation of variables for model building\n",
    "X_norm = intern_train_norm[:, 0:53]\n",
    "y_norm = intern_train_norm[:, 53]\n",
    "\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y_norm, test_size=0.3, \n",
    "                                                                        random_state=0)\n",
    "\n",
    "regress_norm = LinearRegression() \n",
    "regress_norm.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred_norm = regress_norm.predict(X_test_norm)\n",
    "\n",
    "# Comparison of actual values ​​with predicted values\n",
    "comparison_norm = pd.DataFrame({'Actual': y_test_norm, 'Predicted': y_pred_norm}) \n",
    "print('Comparison of actual values ​​with predicted values\\n', \n",
    "      comparison_norm)\n",
    "print('\\n Descriptive statistics data normalization\\n', comparison_norm.describe())\n",
    "\n",
    "# Return original data\n",
    "return_original_data = scaler.inverse_transform(intern_train_norm)\n",
    "\n",
    "print('\\nRoot Mean Squared Error:\\n', \n",
    "      np.sqrt(metrics.mean_squared_error(y_test_norm, y_pred_norm)))\n",
    "\n",
    "model_norm = sm.OLS(comparison_norm['Actual'], comparison_norm['Predicted'])\n",
    "results_norm = model_norm.fit()\n",
    "print(results_norm.summary())\n",
    "\n",
    "################\n",
    "print('\\nCreating a model on the data \"internship_hidden_test\" (10 000)')\n",
    "# Creating a model on the data 'internship_hidden_test' (10 000)\n",
    "# Open data\n",
    "intern_test = pd.read_csv('C:\\\\Users\\\\pipem\\\\Desktop\\\\Study\\\\Quantum internship\\\\internship_hidden_test.csv')\n",
    "\n",
    "# Predict with model on the internship_train\n",
    "y_target = pd.DataFrame(regress.predict(intern_test))\n",
    "print(y_target)\n",
    "print('\\n Descriptive statistics\\n',y_target.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b13e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
